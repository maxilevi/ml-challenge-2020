{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import helpers\n",
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import pickle\n",
    "from sklearn.metrics.pairwise import linear_kernel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST = False\n",
    "FACTORS = 100\n",
    "EPOCHS = 25\n",
    "ITEMS_PER_SEARCH = 5\n",
    "ITEM_CANDIDATES_PER_USER = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = helpers.load_items_df()\n",
    "items_dict = helpers.load_items()\n",
    "domain_item_dict = helpers.load_domain_item_dict(items_dict)\n",
    "all_items = list(items_dict.keys())\n",
    "items_vectorizer, transformed_items, documents_to_item = helpers.vectorize_items(items_dict)\n",
    "\n",
    "interactions_train = helpers.load_interactions_df()\n",
    "if TEST:\n",
    "    interactions_test = helpers.load_interactions_test_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_sold = interactions_train[interactions_train['event_type'] != 'search']['item_id'].value_counts().to_dict()\n",
    "most_sold = {int(k): most_sold[k] for k in most_sold.keys()}\n",
    "for k in items_dict.keys():\n",
    "    if k not in most_sold:\n",
    "        most_sold[k] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _normalize(item_title):\n",
    "    return item_title.upper().strip().replace('.', '').replace('_', '').replace('?', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.45 s, sys: 562 ms, total: 3.02 s\n",
      "Wall time: 3.11 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "847418"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "search_queries = list(set([_normalize(x).strip() for x in interactions_train[interactions_train['event_type'] == 'search']['item_id'].dropna().unique()]))\n",
    "len(search_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_search_queries = sorted(search_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "start = 0\n",
    "step = 10000\n",
    "indexed_results = {}\n",
    "for i in range(start, len(sorted_search_queries)):\n",
    "    q = sorted_search_queries[i]\n",
    "    indexed_results[q] = process_search(q)\n",
    "    if i % step == 0 and i > 0:\n",
    "        print(f'Saving pickle [{i-step}-{i}] with {len(indexed_results)} elements...')\n",
    "        with open(f'./data/search/search[{i-step}-{i}].pickle', 'wb') as handle:\n",
    "            pickle.dump(indexed_results, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        print('Saved pickle!')\n",
    "        indexed_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'': [2010306, 815312, 1961286, 193815, 36911],\n",
       " '( L 290 ) PROPAGANDA ANTIGA TERGAL PERVINC 70 PUBLICACOES OUTROS': [1739031,\n",
       "  1963691,\n",
       "  1243985,\n",
       "  12559,\n",
       "  1513209],\n",
       " ',': [2010306, 815312, 1961286, 193815, 36911],\n",
       " ', A': [2010306, 815312, 1961286, 193815, 36911],\n",
       " ',,': [2010306, 815312, 1961286, 193815, 36911],\n",
       " ',,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,': [2010306,\n",
       "  815312,\n",
       "  1961286,\n",
       "  193815,\n",
       "  36911],\n",
       " ',,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,': [2010306,\n",
       "  815312,\n",
       "  1961286,\n",
       "  193815,\n",
       "  36911],\n",
       " '0': [2010306, 815312, 1961286, 193815, 36911],\n",
       " '0 ANZOL MARINE SPORTS 10': [666576, 1890990, 19219, 976817, 1234964],\n",
       " '0 KM': [1662898, 1158321, 402296, 658960, 286219]}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexed_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>event_type</th>\n",
       "      <th>event_timestamp</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>RELOGIO SMARTWATCH</td>\n",
       "      <td>search</td>\n",
       "      <td>2019-10-19T11:26:07.063-0400</td>\n",
       "      <td>1748830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>DESMAMADEIRA ELETRICA</td>\n",
       "      <td>search</td>\n",
       "      <td>2019-10-07T09:45:29.322-0400</td>\n",
       "      <td>228737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>DESMAMADEIRA ELETRICA</td>\n",
       "      <td>search</td>\n",
       "      <td>2019-10-07T09:46:17.100-0400</td>\n",
       "      <td>228737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>DESMAMADEIRA ELETRICA</td>\n",
       "      <td>search</td>\n",
       "      <td>2019-10-07T09:46:19.173-0400</td>\n",
       "      <td>228737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>DESMAMADEIRA ELETRICA</td>\n",
       "      <td>search</td>\n",
       "      <td>2019-10-07T18:53:20.113-0400</td>\n",
       "      <td>228737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11999155</th>\n",
       "      <td>413160</td>\n",
       "      <td>ALUGUEL BOB CAT ESCAVADEIRA</td>\n",
       "      <td>search</td>\n",
       "      <td>2019-10-15T07:14:39.241-0400</td>\n",
       "      <td>2022477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11999156</th>\n",
       "      <td>413161</td>\n",
       "      <td>XAOMI</td>\n",
       "      <td>search</td>\n",
       "      <td>2019-10-03T21:15:49.220-0400</td>\n",
       "      <td>1111021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11999157</th>\n",
       "      <td>413161</td>\n",
       "      <td>XAOMI</td>\n",
       "      <td>search</td>\n",
       "      <td>2019-10-03T21:15:52.335-0400</td>\n",
       "      <td>1111021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11999158</th>\n",
       "      <td>413161</td>\n",
       "      <td>XAOMI</td>\n",
       "      <td>search</td>\n",
       "      <td>2019-10-03T21:16:33.369-0400</td>\n",
       "      <td>1111021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11999159</th>\n",
       "      <td>413162</td>\n",
       "      <td>COTONETE FINO</td>\n",
       "      <td>search</td>\n",
       "      <td>2019-10-01T20:13:11.202-0400</td>\n",
       "      <td>1212472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6069149 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          user_id                      item_id event_type  \\\n",
       "2               0           RELOGIO SMARTWATCH     search   \n",
       "20              1        DESMAMADEIRA ELETRICA     search   \n",
       "22              1        DESMAMADEIRA ELETRICA     search   \n",
       "23              1        DESMAMADEIRA ELETRICA     search   \n",
       "25              1        DESMAMADEIRA ELETRICA     search   \n",
       "...           ...                          ...        ...   \n",
       "11999155   413160  ALUGUEL BOB CAT ESCAVADEIRA     search   \n",
       "11999156   413161                        XAOMI     search   \n",
       "11999157   413161                        XAOMI     search   \n",
       "11999158   413161                        XAOMI     search   \n",
       "11999159   413162                COTONETE FINO     search   \n",
       "\n",
       "                       event_timestamp   target  \n",
       "2         2019-10-19T11:26:07.063-0400  1748830  \n",
       "20        2019-10-07T09:45:29.322-0400   228737  \n",
       "22        2019-10-07T09:46:17.100-0400   228737  \n",
       "23        2019-10-07T09:46:19.173-0400   228737  \n",
       "25        2019-10-07T18:53:20.113-0400   228737  \n",
       "...                                ...      ...  \n",
       "11999155  2019-10-15T07:14:39.241-0400  2022477  \n",
       "11999156  2019-10-03T21:15:49.220-0400  1111021  \n",
       "11999157  2019-10-03T21:15:52.335-0400  1111021  \n",
       "11999158  2019-10-03T21:16:33.369-0400  1111021  \n",
       "11999159  2019-10-01T20:13:11.202-0400  1212472  \n",
       "\n",
       "[6069149 rows x 5 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process_search(text):\n",
    "    query = items_vectorizer.transform([text]).astype(np.float32)\n",
    "    results = linear_kernel(transformed_items, query)\n",
    "    return [documents_to_item[x] for x in np.argsort(results.flatten())[-ITEMS_PER_SEARCH:][::-1]]\n",
    "    #most_sold_sorted = sorted([(most_sold[documents_to_item[x]], x) for x in np.argsort(results.flatten())[-5:]], key=lambda x: -x[0])\n",
    "    #return [documents_to_item[x[1]] for x in most_sold_sorted[:ITEMS_PER_SEARCH]]\n",
    "\n",
    "interactions_train[interactions_train['event_type'] == 'search']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_item_features():\n",
    "    items_df = items[['item_id', 'domain_id', 'price', 'condition']].copy()\n",
    "\n",
    "    domains = items.domain_id.unique() \n",
    "    m = int(math.log2(len(domains)) + 1)\n",
    "    columns = {f'domain_bit_{i}': [] for i in range(m)}\n",
    "    indexed_domains = {domains[i]: i for i in range(len(domains))}\n",
    "\n",
    "    def domain_apply(x):\n",
    "        arr = bin_array(indexed_domains[x], m)\n",
    "        for j in range(m):\n",
    "            columns[f'domain_bit_{j}'].append(arr[j])\n",
    "\n",
    "    items_df['domain_id'].apply(domain_apply)\n",
    "\n",
    "    for k in columns.keys():\n",
    "        items_df[k] = columns[k]\n",
    "\n",
    "    items_df['condition'] = items_df['condition'].apply(lambda x: 1 if x == 'new' else 0)\n",
    "    items_df = items_df.drop(columns=['domain_id'])\n",
    "    return items_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_interactions(df):\n",
    "    search_mask = df['event_type'] == 'search'\n",
    "    search_events = df[search_mask]\n",
    "    item_events = df[~search_mask]\n",
    "    ## TODO\n",
    "    final = item_events\n",
    "    search_events.apply(, axis=1)\n",
    "    return final[['user_id', 'item_id', 'event_timestamp']]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_candidate_pairs(users):\n",
    "    users_column = []\n",
    "    items_column = []\n",
    "    user_lengths = []\n",
    "    for u in users:\n",
    "        candidates = get_candidates(u)\n",
    "        items_column += candidates\n",
    "        users_column += [u] * len(candidates)\n",
    "        user_lengths.append((u, len(candidates)))\n",
    "    pairs = pd.DataFrame({'user_id': users_column, 'item_id': items_column})\n",
    "    return pairs, user_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_recommendations(recommendations_pairs, user_lengths):\n",
    "    offset = 0\n",
    "    recommendations = {}\n",
    "    for user, user_len in user_lengths:\n",
    "        user_recs = recommendations_pairs[offset:offset+user_len]\n",
    "        ranked_recs = np.argsort(user_recs)[::-1]\n",
    "        top_10 = [x for x in ranked_recs if not np.isnan(user_recs[x])][:10]\n",
    "        recommendations[user] = [items_column[x + offset] for x in top_10]\n",
    "        offset += user_len\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_domains_from_items(items):\n",
    "    return set(items_dict[int(item)]['domain_id'] for item in items)\n",
    "\n",
    "def get_candidates(user):\n",
    "    items_interacted = event_dict[user] if user in event_dict else set()\n",
    "    domains = get_domains_from_items(items_interacted) if items_interacted else top_domains\n",
    "    k = ITEM_CANDIDATES_PER_USER - len(items_interacted)\n",
    "    if k > 0:\n",
    "        items_for_domains = [domain_top_items[d] for d in domains]\n",
    "        item_universe = sum(items_for_domains, [])\n",
    "        if not item_universe:\n",
    "            item_universe = all_items\n",
    "        extra_items = random.choices(item_universe, k=k)\n",
    "        \n",
    "        for item in extra_items:\n",
    "            items_interacted.add(item)\n",
    "            \n",
    "    return [str(x) for x in items_interacted]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_interactions(i1, i2):\n",
    "    i2c['user_id'] += i1c.shape[0]\n",
    "    return i1.append(i2c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = None\n",
    "interactions = None\n",
    "item_features = encode_item_features()\n",
    "sample_weights = None\n",
    "user_features = None\n",
    "\n",
    "if TEST:\n",
    "    interactions = combine_interactions(interactions_train, interactions_test)\n",
    "    users = interactions_test.user_id.unique() + interactions_train.shape[0]\n",
    "else:\n",
    "    interactions = interactions_train\n",
    "    users = interactions_train.user_id.unique()\n",
    "    \n",
    "interactions = encode_interactions(interactions)\n",
    "event_dict = interactions.groupby('user_id')['item_id'].unique().apply(set).to_dict()\n",
    "domain_top_items = helpers.load_top_items(interactions, domain_item_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rankfm\n",
      "  Downloading rankfm-0.2.5.tar.gz (145 kB)\n",
      "\u001b[K     |████████████████████████████████| 145 kB 421 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.15 in /opt/conda/lib/python3.7/site-packages (from rankfm) (1.18.5)\n",
      "Requirement already satisfied: pandas>=0.24 in /opt/conda/lib/python3.7/site-packages (from rankfm) (1.1.3)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.7/site-packages (from pandas>=0.24->rankfm) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=0.24->rankfm) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas>=0.24->rankfm) (1.14.0)\n",
      "Building wheels for collected packages: rankfm\n",
      "  Building wheel for rankfm (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for rankfm: filename=rankfm-0.2.5-cp37-cp37m-linux_x86_64.whl size=385880 sha256=1ef3a985f2822cde3f7729f976f3c039be3ac60a1e3dfe69b9630bee221879b7\n",
      "  Stored in directory: /root/.cache/pip/wheels/99/5f/9d/caa74d8a3cad3dcc3ed9e02d27e7bc18d0ccd1dd5ed1fcdb99\n",
      "Successfully built rankfm\n",
      "Installing collected packages: rankfm\n",
      "Successfully installed rankfm-0.2.5\n"
     ]
    }
   ],
   "source": [
    "!pip install rankfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rankfm.rankfm import RankFM\n",
    "from rankfm.evaluation import hit_rate, reciprocal_rank, discounted_cumulative_gain, precision, recall, diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<rankfm.rankfm.RankFM at 0x7fbaa6de2750>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = RankFM(factors=FACTORS, loss='warp', max_samples=20, alpha=0.01, sigma=0.1, learning_rate=0.10, learning_schedule='invscaling')\n",
    "model.fit(interactions_train, epochs=EPOCHS, verbose=True, user_features=user_features, item_features=item_features, sample_weight=sample_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create item users pairs to feed the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pairs, user_lengths = build_candidate_pairs(users)\n",
    "recommendations_pairs = model.predict(pairs, cold_start='nan')\n",
    "recommendations = build_recommendations(recommendations_pairs, user_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23.4 s, sys: 121 ms, total: 23.5 s\n",
      "Wall time: 23.4 s\n"
     ]
    }
   ],
   "source": [
    "assert recommendations == len(users)\n",
    "assert all(len(recommendations[k]) == 10 for k in recommendations.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring (if training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not TEST:\n",
    "    user_target_dict = interactions.groupby('user_id')['target'].unique().apply(lambda x: x).to_dict()\n",
    "    print(helpers.ndcg_score(recommendations, user_target_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating submit (if testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TEST:\n",
    "    submit = pd.DataFrame(recommendations)\n",
    "    print(f'Submit shape is {submit.shape}')\n",
    "    assert submit.shape == (10, 177070)\n",
    "    submit.transpose().to_csv('submit.csv', index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
